{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PropertyBot Data Ingestion and Enrichment Pipeline\n",
    "\n",
    "\n",
    "* [Creating Listind Dictionary with Property Listings AND Details](##Creating-Listing-Dictionary-with-Property-Listings-AND-Details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor, ImageFont\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/root/propertybot/data-engineering/data_engineering/config.py'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"propertybot-v3\"\n",
    "PREFIX = \"data/raw/listings/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s3 = boto3.resource('s3')  \n",
    "\n",
    "def get_listing(city, state_code, rent_or_sale):\n",
    "    \"\"\"\n",
    "    Retrieves listing data for a city. The data can be either for homes currently \"for sale\", \"for rent\", or \"that recently sold\". \n",
    "    The type of properties returned are only \"single family\" or \"multi family\" properties. \n",
    "    \n",
    "    Args:\n",
    "    city: The city for you are searching properties for.\n",
    "    state: The state you are searching property for.\n",
    "    rent_or_sale: you can specify \"rent\" = current properties for rent, \"sale\" = current properties for sale, \"sold\" = recently sold homes.\n",
    "\n",
    "    Returns:\n",
    "        A json file is returned with basic listing data.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if rent_or_sale == \"rent\":\n",
    "        url = \"https://realty-in-us.p.rapidapi.com/properties/v2/list-for-rent\"\n",
    "        sort=\"newest\"\n",
    "    elif rent_or_sale == \"sale\":\n",
    "        url = \"https://realty-in-us.p.rapidapi.com/properties/v2/list-for-sale\"\n",
    "        sort=\"newest\"\n",
    "    elif rent_or_sale == \"sold\":\n",
    "        url = \"https://realty-in-us.p.rapidapi.com/properties/v2/list-sold\"\n",
    "        sort=\"sold_date\"\n",
    "           \n",
    "        \n",
    "    querystring = {\"city\":city,\"state_code\":state_code,\"offset\":\"0\",\"limit\":200,\"sort\":sort, \"prop_type\":\"single_family, multi_family\"}\n",
    "    headers = {\n",
    "        'x-rapidapi-key': config.api_key_rapid_api_realtyapi,\n",
    "        'x-rapidapi-host': config.api_host_rapid_api_realtyapi\n",
    "        }    \n",
    "    \n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    print(\"INFO: collecting data from {0},{1}, sorted by {2}\".format(city, state_code, sort))\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_details(property_id):\n",
    "    \"\"\"\n",
    "    Gets property details from a listing\n",
    "    \n",
    "    Args:\n",
    "        property_id: the property id from the listing agreements.\n",
    "\n",
    "    Returns:\n",
    "        JSON document with rich property details.\n",
    "    \n",
    "    \"\"\"\n",
    "    querystring = {\"property_id\":property_id}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-host': config.api_host_rapid_api_realtyapi,\n",
    "        'x-rapidapi-key': config.api_key_rapid_api_realtyapi\n",
    "        }\n",
    "\n",
    "    response = requests.request(\"GET\", \"https://realty-in-us.p.rapidapi.com/properties/v2/detail\", headers=headers, params=querystring)\n",
    "  \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Listing Dictionary with Property Listings AND Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_listing_dict(properties):\n",
    "    listings_dict = {}\n",
    "    offset = [0,1]\n",
    "\n",
    "    for item in tqdm(properties):\n",
    "        try:\n",
    "            #gettign necessary data\n",
    "            property_id = item['property_id']\n",
    "            listing = dict(item)\n",
    "            property_details = dict(get_property_details(property_id=property_id))\n",
    "\n",
    "            #merging two dictionary responses\n",
    "            listing.update(property_details)\n",
    "\n",
    "            #adding entry into master listing dictionary\n",
    "            listings_dict[property_id] = listing\n",
    "        except:\n",
    "            print(\"ERROR: not able to retrieve last item\")\n",
    "    return listings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Images from Listing Dictionary, Downloading Images, Saving to S3, and Recording S3 Location in Listing Dictionary for Computer Vision Model to Work off S3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_listings(listings_dict):\n",
    "    image_url_dict = {}\n",
    "    image_public_url_dict = {}\n",
    "\n",
    "    for key,value in tqdm(listings_dict.items()):\n",
    "\n",
    "        #extractign simple property\n",
    "        try:\n",
    "            property_details = value['properties'][0]\n",
    "        except:\n",
    "            print(\"Not all properties have details\")\n",
    "\n",
    "        try: # not all listing have pictures, so this try/except block is needed\n",
    "            photo_data = property_details['photos']\n",
    "            s3_urls = []\n",
    "            s3_public_urls = []\n",
    "            urls = []\n",
    "\n",
    "\n",
    "            #creating a list of urls for external images\n",
    "            for item in photo_data:\n",
    "                urls.append(item['href'])\n",
    "\n",
    "            # downloading images from urls and creating a list of urls in s3 where data are to be stored\n",
    "            counter = 0\n",
    "            for url in urls:\n",
    "                urllib.request.urlretrieve(url, \"temp_data/{0}_{1}.png\".format(key, counter))\n",
    "                s3_urls.append(\"s3://propertybot-v3/data/raw/images/{0}_{1}.png\".format(key, counter))\n",
    "                s3_public_urls.append(\"https://propertybot-v3.s3.amazonaws.com/data/raw/images/{0}_{1}.png\".format(key, counter))\n",
    "                counter = counter + 1\n",
    "\n",
    "            image_url_dict[key] = s3_urls\n",
    "            image_public_url_dict[key] = s3_public_urls\n",
    "\n",
    "        except:\n",
    "            print(\"No photo data\")\n",
    "            image_url_dict[key] = s3_urls\n",
    "            \n",
    "    for k,v in tqdm(listings_dict.items()):\n",
    "        listings_dict[k]['s3_image_urls'] = image_url_dict.get(k)\n",
    "        listings_dict[k]['s3_public_urls'] = image_public_url_dict.get(k)\n",
    "            \n",
    "    return listings_dict, image_url_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(project_arn, model_arn, version_name, min_inference_units):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    try:\n",
    "        # Start the model\n",
    "        print('Starting model: ' + model_arn)\n",
    "        response=client.start_project_version(ProjectVersionArn=model_arn, MinInferenceUnits=min_inference_units)\n",
    "        # Wait for the model to be in the running state\n",
    "        project_version_running_waiter = client.get_waiter('project_version_running')\n",
    "        project_version_running_waiter.wait(ProjectArn=project_arn, VersionNames=[version_name])\n",
    "\n",
    "        #Get the running status\n",
    "        describe_response=client.describe_project_versions(ProjectArn=project_arn,\n",
    "            VersionNames=[version_name])\n",
    "        for model in describe_response['ProjectVersionDescriptions']:\n",
    "            print(\"Status: \" + model['Status'])\n",
    "            print(\"Message: \" + model['StatusMessage']) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Done...')\n",
    "    \n",
    "def main_start_model():\n",
    "    project_arn='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/1631041410077'\n",
    "    model_arn='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/version/propertybot-v3-rehab-rekognition.2021-09-07T12.03.54/1631041434161'\n",
    "    min_inference_units=1 \n",
    "    version_name='propertybot-v3-rehab-rekognition.2021-09-07T12.03.54'\n",
    "    start_model(project_arn, model_arn, version_name, min_inference_units)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Computer Vision Model To Label Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(bucket,photo,response):\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3')\n",
    "\n",
    "    s3_object = s3_connection.Object(bucket,photo)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "\n",
    "    # Ready image to draw bounding boxes on it.\n",
    "    imgWidth, imgHeight = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # calculate and display bounding boxes for each detected custom label\n",
    "    print('Detected custom labels for ' + photo)\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        print('Label ' + str(customLabel['Name']))\n",
    "        print('Confidence ' + str(customLabel['Confidence']))\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left = imgWidth * box['Left']\n",
    "            top = imgHeight * box['Top']\n",
    "            width = imgWidth * box['Width']\n",
    "            height = imgHeight * box['Height']\n",
    "\n",
    "            fnt = ImageFont.truetype('/Library/Fonts/Arial.ttf', 50)\n",
    "            draw.text((left,top), customLabel['Name'], fill='#00d400', font=fnt)\n",
    "\n",
    "            print('Left: ' + '{0:.0f}'.format(left))\n",
    "            print('Top: ' + '{0:.0f}'.format(top))\n",
    "            print('Label Width: ' + \"{0:.0f}\".format(width))\n",
    "            print('Label Height: ' + \"{0:.0f}\".format(height))\n",
    "\n",
    "            points = (\n",
    "                (left,top),\n",
    "                (left + width, top),\n",
    "                (left + width, top + height),\n",
    "                (left , top + height),\n",
    "                (left, top))\n",
    "            draw.line(points, fill='#00d400', width=5)\n",
    "\n",
    "    image.show()\n",
    "\n",
    "def show_custom_labels(model,bucket,photo, min_confidence):\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    #Call DetectCustomLabels\n",
    "    response = client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "        MinConfidence=min_confidence,\n",
    "        ProjectVersionArn=model)\n",
    "\n",
    "    # For object detection use case, uncomment below code to display image.\n",
    "    # display_image(bucket,photo,response)\n",
    "\n",
    "    return response['CustomLabels']\n",
    "\n",
    "def analyze_image(bucket, photo):\n",
    "\n",
    "    bucket=bucket\n",
    "    photo=photo\n",
    "    model='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/version/propertybot-v3-rehab-rekognition.2021-09-07T12.03.54/1631041434161'\n",
    "    min_confidence=80\n",
    "\n",
    "    labels=show_custom_labels(model,bucket,photo, min_confidence)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Computer Vision Model on ALL of the images/properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_on_images(image_url_dict, listings_dict):\n",
    "    tagged_image_dict = {}\n",
    "\n",
    "    for k,v in tqdm(image_url_dict.items()):\n",
    "        for url in v:\n",
    "            temp_labels =[]\n",
    "            prefix = url.replace(\"s3://propertybot-v3/\", \"\")\n",
    "            temp_labels.append(analyze_image(bucket=\"propertybot-v3\", photo=prefix))\n",
    "            tagged_image_dict[url] = temp_labels\n",
    "            \n",
    "    for k,v in listings_dict.items():\n",
    "        big_dict = {}\n",
    "\n",
    "\n",
    "        for url in listings_dict[k]['s3_image_urls']:\n",
    "            try:\n",
    "                big_dict[url]=tagged_image_dict[url]\n",
    "\n",
    "            except: #this should never happeng because all of the urls in the tagged_image_dict come from the listing_dict, so there should always be a match\n",
    "                big_dict[url]=None\n",
    "\n",
    "        listings_dict[k]['labeled_photos'] = big_dict\n",
    "    return listings_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Tagged Images with Listing by joining on s3 path file, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_model(model_arn):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    print('Stopping model:' + model_arn)\n",
    "\n",
    "    #Stop the model\n",
    "    try:\n",
    "        response=client.stop_project_version(ProjectVersionArn=model_arn)\n",
    "        status=response['Status']\n",
    "        print ('Status: ' + status)\n",
    "    except Exception as e:  \n",
    "        print(e)  \n",
    "\n",
    "    print('Done...')\n",
    "    \n",
    "def main_stop_model():\n",
    "    \n",
    "    model_arn='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/version/propertybot-v3-rehab-rekognition.2021-09-07T12.03.54/1631041434161'\n",
    "    stop_model(model_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Enriched Data to DynamoDB for Web Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_property(record, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    table = dynamodb.Table('properties_enriched')\n",
    "    response = table.put_item(\n",
    "       Item=record\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_data_to_dynamoDB(listings_dict):\n",
    "    for k,v in listings_dict.items():\n",
    "        payload = {}\n",
    "        payload['property_id'] = k\n",
    "        payload['property_info'] = v\n",
    "        print(\"INFO: saving data for property_id: {0}\".format(k))\n",
    "\n",
    "        ddb_data = json.loads(json.dumps(payload), parse_float=Decimal) #had to parse float decimal because files could not be saved to DynamoDB\n",
    "        put_property(record=ddb_data)\n",
    "        time.sleep(1) #had to a\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function that Does the Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(city, state_code, rent_or_sale):\n",
    "    s3 = boto3.resource('s3')\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    \n",
    "    print(\"INFO: START pullng data {0} for {1},{2}\".format(rent_or_sale, city, state_code))\n",
    "    response = get_listing(city=city, state_code=state_code, rent_or_sale=rent_or_sale)\n",
    "    properties = response['properties']\n",
    "    listings_dict = create_listing_dict(properties=properties)\n",
    "    print(\"Done...\")\n",
    "    \n",
    "    \n",
    "    print(\"INFO: extracting images from listings...\")\n",
    "    #extracting images and saves to s3, saves location in listings_dict\n",
    "    listings_dict, image_url_dict = extract_images_from_listings(listings_dict)\n",
    "    os.system(\"aws s3 mv temp_data s3://propertybot-v3/data/raw/images --recursive --quiet\")\n",
    "    print(\"Done...\")\n",
    "    \n",
    "    print(\"INFO: running computer vision on images...\")\n",
    "    #running AI/computer vision on images in s3 and saves label in listings_dict\n",
    "    main_start_model()\n",
    "    \n",
    "    \n",
    "    listings_dict = ai_on_images(image_url_dict=image_url_dict, listings_dict=listings_dict)\n",
    "    main_stop_model()\n",
    "    print(\"Done...\")\n",
    "    \n",
    "    #saving enriched listings_dict to dynamoDB table\n",
    "    print(\"INFO: saving enriched JSON to DynamoDB table...\")\n",
    "    saving_data_to_dynamoDB(listings_dict=listings_dict)\n",
    "    print(\"Done...\")\n",
    "    \n",
    "    print(\"INFO: DONE pullng data {0} for {1},{2}\".format(rent_or_sale, city, state_code))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: START pullng data sale for Cleveland,OH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: collecting data from Cleveland,OH, sorted by newest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:44<00:00,  1.12s/it]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n",
      "INFO: extracting images from listings...\n",
      "No photo data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 's3_urls' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-84ca1f82c825>\u001b[0m in \u001b[0;36mextract_images_from_listings\u001b[0;34m(listings_dict)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# not all listing have pictures, so this try/except block is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mphoto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0ms3_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'photos'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-ccd7da9780f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cleveland\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"OH\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrent_or_sale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-119-cbdf785ad6f4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(city, state_code, rent_or_sale)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INFO: extracting images from listings...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#extracting images and saves to s3, saves location in listings_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlistings_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_url_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_images_from_listings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistings_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aws s3 mv temp_data s3://propertybot-v3/data/raw/images --recursive --quiet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-84ca1f82c825>\u001b[0m in \u001b[0;36mextract_images_from_listings\u001b[0;34m(listings_dict)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No photo data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mimage_url_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3_urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistings_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 's3_urls' referenced before assignment"
     ]
    }
   ],
   "source": [
    "main(city=\"Cleveland\", state_code=\"OH\", rent_or_sale=\"sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
