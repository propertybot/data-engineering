{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PropertyBot Data Ingestion and Enrichment Pipeline\n",
    "\n",
    "\n",
    "* [Creating Listind Dictionary with Property Listings AND Details](##Creating-Listing-Dictionary-with-Property-Listings-AND-Details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor, ImageFont\n",
    "from decimal import Decimal\n",
    "from description_nlp import fetch_description_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"propertybot-v3\"\n",
    "PREFIX = \"data/raw/listings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s3 = boto3.resource('s3')  \n",
    "\n",
    "def get_listing(city, state_code, rent_or_sale, offset, limit):\n",
    "    \"\"\"\n",
    "    Retrieves listing data for a city. The data can be either for homes currently \"for sale\", \"for rent\", or \"that recently sold\". \n",
    "    The type of properties returned are only \"single family\" or \"multi family\" properties. \n",
    "    \n",
    "    Args:\n",
    "    city: The city for you are searching properties for.\n",
    "    state: The state you are searching property for.\n",
    "    rent_or_sale: you can specify \"rent\" = current properties for rent, \"sale\" = current properties for sale, \"sold\" = recently sold homes.\n",
    "\n",
    "    Returns:\n",
    "        A json file is returned with basic listing data.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if rent_or_sale == \"rent\":\n",
    "        url = \"https://realty-in-us.p.rapidapi.com/properties/v2/list-for-rent\"\n",
    "        sort=\"newest\"\n",
    "    elif rent_or_sale == \"sale\":\n",
    "        url = \"https://realty-in-us.p.rapidapi.com/properties/v2/list-for-sale\"\n",
    "        sort=\"newest\"\n",
    "    elif rent_or_sale == \"sold\":\n",
    "        url = \"https://realty-in-us.p.rapidapi.com/properties/v2/list-sold\"\n",
    "        sort=\"sold_date\"\n",
    "           \n",
    "        \n",
    "    querystring = {\"city\":city,\"state_code\":state_code,\"offset\":offset,\"limit\":limit,\"sort\":sort, \"prop_type\":\"single_family, multi_family\"}\n",
    "    headers = {\n",
    "        'x-rapidapi-key': config.api_key_rapid_api_realtyapi,\n",
    "        'x-rapidapi-host': config.api_host_rapid_api_realtyapi\n",
    "        }    \n",
    "    \n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    print(\"INFO: collecting data from {0},{1}, sorted by {2}\".format(city, state_code, sort))\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_details(property_id):\n",
    "    \"\"\"\n",
    "    Gets property details from a listing\n",
    "    \n",
    "    Args:\n",
    "        property_id: the property id from the listing agreements.\n",
    "\n",
    "    Returns:\n",
    "        JSON document with rich property details.\n",
    "    \n",
    "    \"\"\"\n",
    "    querystring = {\"property_id\":property_id}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-host': config.api_host_rapid_api_realtyapi,\n",
    "        'x-rapidapi-key': config.api_key_rapid_api_realtyapi\n",
    "        }\n",
    "\n",
    "    response = requests.request(\"GET\", \"https://realty-in-us.p.rapidapi.com/properties/v2/detail\", headers=headers, params=querystring)\n",
    "  \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Listing Dictionary with Property Listings AND Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_listing_dict(properties):\n",
    "    listings_dict = {}\n",
    "\n",
    "    for item in tqdm(properties):\n",
    "        try:\n",
    "            #gettign necessary data\n",
    "            property_id = item['property_id']\n",
    "            listing = dict(item)\n",
    "            property_details = dict(get_property_details(property_id=property_id))\n",
    "\n",
    "            #merging two dictionary responses\n",
    "            listing.update(property_details)\n",
    "\n",
    "            #adding entry into master listing dictionary\n",
    "            listings_dict[property_id] = listing\n",
    "        except:\n",
    "            print(\"ERROR: not able to retrieve last item\")\n",
    "    return listings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Images from Listing Dictionary, Downloading Images, Saving to S3, and Recording S3 Location in Listing Dictionary for Computer Vision Model to Work off S3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_listings(listings_dict):\n",
    "    image_url_dict = {}\n",
    "    image_public_url_dict = {}\n",
    "    s3_urls = []\n",
    "    s3_public_urls = []\n",
    "    urls = []\n",
    "\n",
    "    for key,value in tqdm(listings_dict.items()):\n",
    "        \n",
    "        #extractign simple property\n",
    "        try:\n",
    "            property_details = value['properties'][0]\n",
    "        except:\n",
    "            print(\"Not all properties have details\")\n",
    "\n",
    "        try: # not all listing have pictures, so this try/except block is needed\n",
    "            photo_data = property_details['photos']\n",
    "\n",
    "            #creating a list of urls for external images\n",
    "            for item in photo_data:\n",
    "                urls.append(item['href'])\n",
    "\n",
    "            # downloading images from urls and creating a list of urls in s3 where data are to be stored\n",
    "            counter = 0\n",
    "            for url in urls:\n",
    "                urllib.request.urlretrieve(url, \"temp_data/{0}_{1}.png\".format(key, counter))\n",
    "                s3_urls.append(\"s3://propertybot-v3/data/raw/images/{0}_{1}.png\".format(key, counter))\n",
    "                s3_public_urls.append(\"https://propertybot-v3.s3.amazonaws.com/data/raw/images/{0}_{1}.png\".format(key, counter))\n",
    "                counter = counter + 1\n",
    "\n",
    "            image_url_dict[key] = s3_urls\n",
    "            image_public_url_dict[key] = s3_public_urls\n",
    "\n",
    "        except:\n",
    "            print(\"No photo data\")\n",
    "            image_url_dict[key] = s3_urls\n",
    "            \n",
    "    for k,v in tqdm(listings_dict.items()):\n",
    "        listings_dict[k]['s3_image_urls'] = image_url_dict.get(k)\n",
    "        listings_dict[k]['s3_public_urls'] = image_public_url_dict.get(k)\n",
    "            \n",
    "    return listings_dict, image_url_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NLP on posted MLS descriptions to get applicable metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_metadata(listings_dict):\n",
    "    for k,v in listings_dict.items():\n",
    "        listings_dict[k]['description_metadata'] = fetch_description_metadata(v)\n",
    "\n",
    "    return listings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(project_arn, model_arn, version_name, min_inference_units):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    try:\n",
    "        # Start the model\n",
    "        print('Starting model: ' + model_arn)\n",
    "        response=client.start_project_version(ProjectVersionArn=model_arn, MinInferenceUnits=min_inference_units)\n",
    "        # Wait for the model to be in the running state\n",
    "        project_version_running_waiter = client.get_waiter('project_version_running')\n",
    "        project_version_running_waiter.wait(ProjectArn=project_arn, VersionNames=[version_name])\n",
    "\n",
    "        #Get the running status\n",
    "        describe_response=client.describe_project_versions(ProjectArn=project_arn,\n",
    "            VersionNames=[version_name])\n",
    "        for model in describe_response['ProjectVersionDescriptions']:\n",
    "            print(\"Status: \" + model['Status'])\n",
    "            print(\"Message: \" + model['StatusMessage']) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Done...')\n",
    "    \n",
    "def main_start_model():\n",
    "    project_arn='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/1631041410077'\n",
    "    model_arn='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/version/propertybot-v3-rehab-rekognition.2021-09-07T12.03.54/1631041434161'\n",
    "    min_inference_units=1 \n",
    "    version_name='propertybot-v3-rehab-rekognition.2021-09-07T12.03.54'\n",
    "    start_model(project_arn, model_arn, version_name, min_inference_units)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Computer Vision Model To Label Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(bucket,photo,response):\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3')\n",
    "\n",
    "    s3_object = s3_connection.Object(bucket,photo)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "\n",
    "    # Ready image to draw bounding boxes on it.\n",
    "    imgWidth, imgHeight = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # calculate and display bounding boxes for each detected custom label\n",
    "    print('Detected custom labels for ' + photo)\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        print('Label ' + str(customLabel['Name']))\n",
    "        print('Confidence ' + str(customLabel['Confidence']))\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left = imgWidth * box['Left']\n",
    "            top = imgHeight * box['Top']\n",
    "            width = imgWidth * box['Width']\n",
    "            height = imgHeight * box['Height']\n",
    "\n",
    "            fnt = ImageFont.truetype('/Library/Fonts/Arial.ttf', 50)\n",
    "            draw.text((left,top), customLabel['Name'], fill='#00d400', font=fnt)\n",
    "\n",
    "            print('Left: ' + '{0:.0f}'.format(left))\n",
    "            print('Top: ' + '{0:.0f}'.format(top))\n",
    "            print('Label Width: ' + \"{0:.0f}\".format(width))\n",
    "            print('Label Height: ' + \"{0:.0f}\".format(height))\n",
    "\n",
    "            points = (\n",
    "                (left,top),\n",
    "                (left + width, top),\n",
    "                (left + width, top + height),\n",
    "                (left , top + height),\n",
    "                (left, top))\n",
    "            draw.line(points, fill='#00d400', width=5)\n",
    "\n",
    "    image.show()\n",
    "\n",
    "def show_custom_labels(model,bucket,photo, min_confidence):\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    #Call DetectCustomLabels\n",
    "    response = client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "        MinConfidence=min_confidence,\n",
    "        ProjectVersionArn=model)\n",
    "\n",
    "    # For object detection use case, uncomment below code to display image.\n",
    "    # display_image(bucket,photo,response)\n",
    "\n",
    "    return response['CustomLabels']\n",
    "\n",
    "def analyze_image(bucket, photo):\n",
    "\n",
    "    bucket=bucket\n",
    "    photo=photo\n",
    "    model='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/version/propertybot-v3-rehab-rekognition.2021-09-07T12.03.54/1631041434161'\n",
    "    min_confidence=80\n",
    "\n",
    "    labels=show_custom_labels(model,bucket,photo, min_confidence)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Computer Vision Model on ALL of the images/properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_on_images(image_url_dict, listings_dict):\n",
    "    tagged_image_dict = {}\n",
    "\n",
    "    for k,v in tqdm(image_url_dict.items()):\n",
    "        for url in v:\n",
    "            temp_labels =[]\n",
    "            prefix = url.replace(\"s3://propertybot-v3/\", \"\")\n",
    "            temp_labels.append(analyze_image(bucket=\"propertybot-v3\", photo=prefix))\n",
    "            tagged_image_dict[url] = temp_labels\n",
    "            \n",
    "    for k,v in listings_dict.items():\n",
    "        big_dict = {}\n",
    "\n",
    "\n",
    "        for url in listings_dict[k]['s3_image_urls']:\n",
    "            try:\n",
    "                big_dict[url]=tagged_image_dict[url]\n",
    "\n",
    "            except: #this should never happeng because all of the urls in the tagged_image_dict come from the listing_dict, so there should always be a match\n",
    "                big_dict[url]=None\n",
    "\n",
    "        listings_dict[k]['labeled_photos'] = big_dict\n",
    "    return listings_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Tagged Images with Listing by joining on s3 path file, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_model(model_arn):\n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    print('Stopping model:' + model_arn)\n",
    "\n",
    "    #Stop the model\n",
    "    try:\n",
    "        response=client.stop_project_version(ProjectVersionArn=model_arn)\n",
    "        status=response['Status']\n",
    "        print ('Status: ' + status)\n",
    "    except Exception as e:  \n",
    "        print(e)  \n",
    "\n",
    "    print('Done...')\n",
    "    \n",
    "def main_stop_model():\n",
    "    \n",
    "    model_arn='arn:aws:rekognition:us-east-1:735074111034:project/propertybot-v3-rehab-rekognition/version/propertybot-v3-rehab-rekognition.2021-09-07T12.03.54/1631041434161'\n",
    "    stop_model(model_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Enriched Data to DynamoDB for Web Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_property(record, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    table = dynamodb.Table('properties_enriched')\n",
    "    response = table.put_item(\n",
    "       Item=record\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_data_to_dynamoDB(listings_dict):\n",
    "    for k,v in listings_dict.items():\n",
    "        payload = {}\n",
    "        payload['property_id'] = k\n",
    "        payload['property_info'] = v\n",
    "        print(\"INFO: saving data for property_id: {0}\".format(k))\n",
    "\n",
    "        ddb_data = json.loads(json.dumps(payload), parse_float=Decimal) #had to parse float decimal because files could not be saved to DynamoDB\n",
    "        put_property(record=ddb_data)\n",
    "        time.sleep(1) #had to a\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function that Does the Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(city, state_code, rent_or_sale, limit, offset, how_many):\n",
    "    s3 = boto3.resource('s3')\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    main_start_model()\n",
    "    \n",
    "    \n",
    "    limit = limit\n",
    "    offset = offset\n",
    "    total = 0\n",
    "    \n",
    "    print(\"INFO: going to get the {0} latest listings...this while take a while\".format(how_many))\n",
    "    while offset <= how_many:\n",
    "        print(\"INFO: START pulling data {0} for {1},{2} with limit {3} and offset {4}\".format(rent_or_sale, city, state_code, limit, offset))\n",
    "        \n",
    "        response = get_listing(city=city, state_code=state_code, rent_or_sale=rent_or_sale, offset=offset, limit=limit)\n",
    "        properties = response['properties']\n",
    "        listings_dict = create_listing_dict(properties=properties)\n",
    "        total = limit + offset\n",
    "        offset = offset + limit\n",
    "        print(\"Done...\")\n",
    "        \n",
    "        print(\"INFO: extracting images from listings...\")\n",
    "        listings_dict, image_url_dict = extract_images_from_listings(listings_dict)\n",
    "        os.system(\"aws s3 mv temp_data s3://propertybot-v3/data/raw/images --recursive --quiet\")\n",
    "        print(\"Done...\")\n",
    "        \n",
    "        print(\"INFO: using NLP to extract metadata from listings...\")\n",
    "        listings_dict = attach_metadata(listings_dict)\n",
    "        print(\"Done...\")\n",
    "        \n",
    "        print(\"INFO: creating labels from images...\")\n",
    "        listings_dict = ai_on_images(image_url_dict=image_url_dict, listings_dict=listings_dict)\n",
    "        print(\"Done...\")\n",
    "        \n",
    "        \n",
    "        print(\"INFO: saving enriched JSON to DynamoDB table...\")\n",
    "        saving_data_to_dynamoDB(listings_dict=listings_dict)\n",
    "        print(\"Done...\")\n",
    "\n",
    "    main_stop_model()\n",
    "    print(\"INFO: DONE pullng data {0} for {1},{2}\".format(rent_or_sale, city, state_code))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(city=\"Cleveland\", state_code=\"OH\", rent_or_sale=\"sale\", limit=1, offset=1, how_many=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
